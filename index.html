<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Beheshteh T. Rakhshan Portfolio</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" rel="stylesheet"/>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet"/>
    <link href="styles.css" rel="stylesheet"/>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="hamburger" onclick="toggleNav()">
                <div></div>
                <div></div>
                <div></div>
            </div>
            <h1>Beheshteh T. Rakhshan</h1>
            <div class="nav">
                <a href="#about">About</a>
                <a href="#news">News</a>
                <a href="#research">Research</a>
                <a href="#talks">Talks</a>
                <a href="#contact">Contact</a>
            </div>
            <div class="social-links">
                <a href="cv.pdf" target="_blank" title="Download CV" class="cv-link">CV</a>
                <a href="https://www.linkedin.com/in/beheshteh-rakhshan/"><i class="fab fa-linkedin"></i></a>
                <a href="https://github.com/brakhshan"><i class="fab fa-github"></i></a>
                <a href="https://scholar.google.com/citations?user=AWGU-v8AAAAJ&hl=en&oi=ao"><i class="fas fa-graduation-cap"></i></a>
            </div>
        </div>
        <div class="mobile-nav" id="mobile-nav">
            <a href="#about">About</a>
            <a href="#news">News</a>
            <a href="#research">Research</a>
            <a href="#talks">Talks</a>
            <a href="#contact">Contact</a>
        </div>
        <div class="overlay" id="overlay"></div>
        <div class="profile">
            <img src="Beheshteh.png" alt="Profile picture of Beheshteh T. Rakhshan" width="150" height="150"/>
            <h2>Beheshteh T. Rakhshan</h2>
            <p>PhD student, University of Montreal & MILA - Québec AI Institute</p>
        </div>
        <div class="content" id="about">
            <h2>About</h2>
            <p>
                I am a PhD student in the theory group at the Department of Computer Science and Operations Research (DIRO) Université de Montréal and MILA, where I am fortunate to be advised by <a href="https://www-labs.iro.umontreal.ca/~grabus/" target="_blank">Guillaume Rabusseau</a>. My research interests lie in the theoretical foundations of machine learning, particularly Randomized algorithms and Tensor Decompositions.<p>
                Prior to joining Mila, I was a PhD student in the Mathematics Department at Purdue University where I was advised by <a href="https://www.cs.purdue.edu/homes/pdrineas/" target="_blank">Petros Drineas</a>, you can read my story <a href="https://www.purdueexponent.org/campus/visa-struggles-prevent-student-from-completing-doctorate/article_c29e92e2-cf28-583e-9b4f-8cc818a4d4fc.html" target="_blank">here</a>.
            </p>
        </div>
        <div class="content" id="news">
            <h2>News</h2>
            <p>March 2025: Mila Women in AI scholarship recipient 8k/year.
            <p>December 2024: Happy to present our work <b> Efficient Leverage Score Sampling for Tensor Train Decomposition</b> in NeurIPS 2024.
            <a href="https://nips.cc/media/PosterPDFs/NeurIPS%202024/94191.png?t=1731648738.6269429">[poster]</a> 
            <p>December 2024: The first draft of our new book, <a href="book.html">Towards Mastering Tensor Networks: A Comprehensive Guide</a>, is now available!</p>
            <p>September 2024: Our paper <b> Efficient Leverage Score Sampling for Tensor Train Decomposition</b> got accepted as a poster to NeurIPS 2024.
                <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/86c1fd74fa25bd6be0072937803e0bd1-Paper-Conference.pdf">[paper]</a> 
                <a href="https://github.com/vbharadwaj-bk/ortho_tt_subspace_embedding">[code]</a>
            </p>
            <p>August 2024: Started an internship at Zapata AI.</p>
            <p>July 2024: Selected to participate in the 2024 Gene Golub SIAM summer school.</p>
            <p>December 2023: Served as a co-organizer for the New In ML workshop, NeurIPS 2023.</p>
            <p>September 2023: Served as a Mila Tensor Networks Reading Group<a href="https://tensor-networks.github.io/"> [More info Here].</a> </p>
            <p>May 2021: IVADO PhD Excellence Scholarship recipient.</p>
        </div>
        <div class="content" id="research">
            <h2>Research</h2>
            <p>
                I am broadly interested in the theory behind Big Data and Machine Learning problems. My research is focused on developing fast and efficient randomized algorithms with tensor networks for large-scale problems. My goal is to develop algorithms with provable guarantees, and accurate and fast solutions to computationally expensive methods by leveraging dimensionality reduction and tensor decompositions' techniques.
            </p>
        </div>
        <div class="content" id="talks">
            <h2>Talks</h2>
            <div class="talk-section">
                <div class="video-section">
                    <div class="video-container">
                        <iframe src="https://www.youtube.com/embed/NNbkcTMJI44" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    </div>
                    <div class="video-explanation">
                        <h3>Spotlight on Beheshteh T. Rakhshan</h3>
                        <p>About Mila and my research interests.</p>
                    </div>
                </div>
            </div>
            <div class="talk-section">
                <div class="video-section">
                    <div class="video-container">
                        <iframe src="https://slideslive.com/embed/38971501" title="Rademacher Random Projections with Tensor Networks" frameborder="0" allow="fullscreen" allowfullscreen></iframe>
                    </div>
                    <div class="video-explanation">
                        <h3>Rademacher Random Projections with Tensor Networks</h3>
                        <p>
                        Random projections have recently emerged as popular techniques in the machine learning community for their ability to reduce 
                        the dimension of very high-dimensional tensors. In this work, we consider a tensorized random projection map relying on Tensor Train (TT) decomposition 
                        where each element of the core tensors is drawn from a Rademacher distribution. Our theoretical results reveal that the Gaussian low-rank tensor represented 
                        in compressed form in TT format can be replaced by a TT tensor with core elements drawn from a Rademacher distribution with the same embedding size. 
                        In addition, we show both theoretically and experimentally, that the tensorized RP in the Matrix Product Operator (MPO) format is not a Johnson-Lindenstrauss transform
                        (JLT) and therefore not a well-suited random projection map.</p>
                            
                         .</p>
                    </div>
                </div>
            </div>
            <div class="talk-section">
                <div class="video-section">
                    <div class="video-container">
                        <iframe src="https://slideslive.com/embed/38930252" title="Tensorized Random Projection Talk" frameborder="0" allow="fullscreen" allowfullscreen></iframe>
                    </div>
                    <div class="video-explanation">
                        <h3>Tensorized Random Projection</h3>
                        <p>
                        In this work, we introduce a novel random projection technique for efficiently reducing the dimension of very high-dimensional tensors.
                        Building upon classical results on Gaussian random projections and Johnson-Lindenstrauss transforms (JLT), we propose two tensorized random projection maps
                        relying on the tensor train (TT) and CP decomposition format, respectively. The two maps offer very low memory requirements and can be applied efficiently 
                        when the inputs are low-rank tensors given in the CP or TT format. Our theoretical analysis shows that the dense Gaussian matrix in JLT can be replaced by a low-rank tensor 
                        implicitly represented in compressed form with random factors, while still approximately preserving the Euclidean distance of the projected inputs. 
                        In addition, our results reveal that the TT format is substantially superior to CP in terms of the size of the random projection needed to achieve the same distortion ratio. 
                        </p>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="content" id="contact">
            <h2>Contact</h2>
            <p>
                Email: <a href="mailto:rakhshab@mila.quebec">rakhshab@mila.quebec</a>
            </p>
        </div>
        <div class="content">
            <img src="footer.svg" alt="Wide SVG representing research or academic work" class="wide-svg"/>
        </div>
    </div>

    <script>
        function toggleNav() {
            var nav = document.getElementById("mobile-nav");
            var overlay = document.getElementById("overlay");
            var hamburger = document.querySelector(".hamburger");
            
            if (nav.style.display === "flex") {
                nav.style.display = "none";
                overlay.style.display = "none";
                hamburger.classList.remove("active");
                document.body.style.overflow = "auto";
            } else {
                nav.style.display = "flex";
                overlay.style.display = "block";
                hamburger.classList.add("active");
                document.body.style.overflow = "hidden";
            }
        }

        // Close mobile nav when a link or overlay is clicked
        document.addEventListener('DOMContentLoaded', function() {
            document.querySelectorAll('.mobile-nav a, #overlay').forEach(element => {
                element.addEventListener('click', () => {
                    var nav = document.getElementById("mobile-nav");
                    var overlay = document.getElementById("overlay");
                    var hamburger = document.querySelector(".hamburger");
                    
                    nav.style.display = "none";
                    overlay.style.display = "none";
                    hamburger.classList.remove("active");
                    document.body.style.overflow = "auto";
                });
            });
        });
    </script>
</body>
</html>
